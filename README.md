# ollamafaissflaskapp
An attempt was made to create an AI-driven research assistant that enables teams to intelligently search, summarize, and cite scientific literature â€” instantly. By integrating local LLMs with semantic search, we eliminate noise, reduce review cycles, and accelerate insight generation across compliance, R&D, and innovation. This platform lays the groundwork for scalable, enterprise-grade knowledge automation.
In technical terms, the enclosed code works with a model of locally installed LLM Laama using ollama model along with vector database faiss and simple flask application
More to come on improving this project to automate the whole process along with agents
